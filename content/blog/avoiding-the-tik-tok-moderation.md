+++
title = "Avoiding TikTok's auto moderation"
abstract = "Nobody outside of TikTok understands the intricacies of their algorithm. That doesn't stop user's from trying."
image_url = "https://awgsalesservices.com/wp-content/uploads/2019/10/TikTok-Logo-1180x655.png"
tags = "technology, human-computer interaction"
date = 2020-09-11
+++

### Preamble

TikTok is some what of a black box. At a glance, it's simple -- it's an algorithm that's fed a slew of data about a user to provide a customized feed. But, once you start interacting with the app, (and espeically start creating content on the app), you begin to realize it's more nuanced than that.

The reach of a creator's content is soley decided and execute by TikTok. The main feed, the For You Page, is populated by an algorithm not a list of subscribed, followed, or friended users.

Creators experience periods of amazing growth and "virality". Then, almost at random, this can be taken away.

If you've used TikTok for any extended period of time, you may have seen a creator say something along the lines of:

> "I've been shadowbanned, if you see this video please interact with it!"

Creators have begun to refer to this dip in engagement as being "shadowbanned". Based on what they've observerd and how their own consumption in the app works, the obvious solution is to ask viewers to interact with you content; somehow try and feed the algorithm positive cues about your content.

As an aside, one of my favorite calls to action I've seen is

> "If you see this, hit share -> other -> copy link"

This is because, I assume, TikTok doesn't know how to weight that interaction. They override buttons for sharing via messages, snapchat, twitter, etc. but once you hit other (and open the system default share sheet) they can't track what you do from there. All they can see is success or failure. If you copy the link, it's a "success"; if you hit cancel, it's a "failure". A sucesful share is most likely a positive input to the algorithm.

---

### Avoiding auto moderation 

That has very little to do with what I'm writing about today but it sets a good stage. Creators walk on egg shells to avoid upsetting the algorithm -- they don't want to send any wrong signals. From a Human-Computer Interaction point of view this is amazing but, again, not directly related to the following.

Many creators, rightfully, believe certain words (traditional curse words, political speech, etc.) can decrease their viewership or outright take down their videos.

Whether this is true or not, creators have begun to use aliases for these words to avoid these automatic filters.

Here are some (explicit) examples:

![leaf emoji instead of weed](/blog-posts/images/avoiding-tik-tok-moderation/0.jpg)

![using @ signs for a](/blog-posts/images/avoiding-tik-tok-moderation/1.jpg)

![even words like homophobic are 'encoded'](/blog-posts/images/avoiding-tik-tok-moderation/2.jpg)

![swapping i with an i-hat](/blog-posts/images/avoiding-tik-tok-moderation/3.jpg)

![u with dots over it, oui'd instead of weed](/blog-posts/images/avoiding-tik-tok-moderation/4.jpg)
> notably, oui'd is a common tiktok alias for weed

![basically using a different language to hide explitaves](/blog-posts/images/avoiding-tik-tok-moderation/5.jpg)

![d3@d p*ff b*rs](/blog-posts/images/avoiding-tik-tok-moderation/6.jpg)

This isn't a new phenomenon, twitter user's often use astricks to hide their tweet from search results. That makes sense; they're hiding from other users searching specific key words.

TikTok is different. Allegedly, the algortihm runs OCR on each video to moderate and propogate content (notably, if the user creates the video within the app, TikTok could have access to the raw string and attach it to the metadata).
